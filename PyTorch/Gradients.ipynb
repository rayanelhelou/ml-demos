{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEghcOiBjZap"
   },
   "source": [
    "In this notebook, we demonstrate how PyTorch can be used to automatically compute gradients of functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYdWTHHdp0d6"
   },
   "source": [
    "**Our example:**\n",
    "\n",
    "If $y = \\sin\\left((wx+b)^2\\right)$, then what are $\\displaystyle \\cfrac{\\partial y}{\\partial w}$ and $\\displaystyle \\cfrac{\\partial y}{\\partial b}$?\n",
    "\n",
    "Here's what we expect, from calculus:\n",
    "\n",
    "\\begin{align}\n",
    "  \\cfrac{\\partial y}{\\partial w} &= 2x(wx+b)\\cos\\left((wx+b)^2\\right) \\\\\n",
    "  \\cfrac{\\partial y}{\\partial b} &= 2(wx+b)\\cos\\left((wx+b)^2\\right)\n",
    "\\end{align}\n",
    "\n",
    "Let's explore what PyTorch produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1588131962690,
     "user": {
      "displayName": "Rayan El Helou",
      "photoUrl": "",
      "userId": "08397691837856645763"
     },
     "user_tz": 300
    },
    "id": "C0WLRVXvuHpj",
    "outputId": "114bfec7-7788-498b-8bde-1cf9a8d811f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: tensor([101.9641], grad_fn=<MulBackward0>)\n",
      "PyTorch:  tensor([101.9641])\n",
      "\n",
      "Expected: tensor([33.9880], grad_fn=<MulBackward0>)\n",
      "PyTorch:  tensor([33.9880])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = 3\n",
    "\n",
    "# w & b, below, are defined as scalars (w = 4, b = 5)\n",
    "# 'requires_grad = True' tells PyTorch that we want to find a derivative with respect to w & b\n",
    "# The gradient is computed below at: 'y.backward()'\n",
    "\n",
    "w = torch.tensor([4.0], requires_grad=True)\n",
    "b = torch.tensor([5.0], requires_grad=True)\n",
    "\n",
    "y = torch.sin((w*x + b)**2)\n",
    "\n",
    "y.backward() # computes the gradients of y with respect to every variable that 'requires_grad' and stores them inside the variable itself.\n",
    "# For example, to access dy/dw, use:   w.grad\n",
    "\n",
    "print('Expected:', 2*x*(w*x + b)*torch.cos((w*x + b)**2))\n",
    "print('PyTorch: ', w.grad)\n",
    "\n",
    "print()\n",
    "print('Expected:', 2*(w*x + b)*torch.cos((w*x + b)**2))\n",
    "print('PyTorch: ', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IuFkHT9r1dvH"
   },
   "source": [
    "# CHALLENGE TO STUDENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fl0790lI7wf2"
   },
   "source": [
    "Can you demonstrate that the expected value for $\\displaystyle \\cfrac{\\partial y}{\\partial x}$ and the one computed by PyTorch are the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvFcXHva1b2V"
   },
   "outputs": [],
   "source": [
    "# Hint: begin by modifying the line of code 'x = 3' from the cell above\n",
    "# Final answer: 135.9522"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Gradients.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
